{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNJ6m4zWL3BDR7AwMm6+9vr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# 04_Transfer_learning_in_TF_part_1_feature_extraction\n","\n","Transfer learning is leveraging a working model's existing architecture and learned patterns for our own problem.\n","\n"],"metadata":{"id":"JznCgOSGzSt-"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"yCy6FQkd1hz5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dowloading and becoming one with the data"],"metadata":{"id":"Zuv9cMLp1oZ_"}},{"cell_type":"code","source":["# Get data (10% of 10 food classes from Food101)\n","import zipfile\n","\n","# Download the data\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","\n","# Unzip the downloaded file\n","zip_ref = zipfile.ZipFile('10_food_classes_10_percent.zip')\n","zip_ref.extractall()\n","zip_ref.close()"],"metadata":{"id":"x_TOpSJC178D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# How many images in each folder?\n","import os\n","\n","# Walk through 10 percent data directory and list number of files\n","for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n","  print(f'There are {len(dirnames)} directories and {len(filenames)} images in {dirpath} .')"],"metadata":{"id":"-pW1upAE4NIh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##  Preparing the data (Creating data loaders)\n","\n","We'll use the `ImageDataGenerator` to load in our images in batches."],"metadata":{"id":"xxJkVsBV5GTg"}},{"cell_type":"code","source":["# Setup data inputs\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","IMAGE_SHAPE = (224,224)\n","BATCH_SIZE = 32\n","\n","train_dir = '10_food_classes_10_percent/train'\n","test_dir = '10_food_classes_10_percent/test/'\n","\n","train_datagen = ImageDataGenerator(rescale= 1/255.)\n","test_datagen = ImageDataGenerator(rescale= 1/255.)\n","\n","print('Training images:')\n","train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n","                                                                                              target_size= IMAGE_SHAPE,\n","                                                                                              batch_size= BATCH_SIZE,\n","                                                                                              class_mode='categorical')\n","\n","print('Testing images:')\n","test_data = test_datagen.flow_from_directory(train_dir,\n","                                             target_size= IMAGE_SHAPE,\n","                                             batch_size= BATCH_SIZE,\n","                                             class_mode='categorical')\n"],"metadata":{"id":"vaYISCXl6hze"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Setting up callbacks"],"metadata":{"id":"YSPC2F3T8GmP"}},{"cell_type":"code","source":["# Create TensorBoard callback (We'll usea a fuction because we need to reate a new one for each model)\n","import datetime\n","\n","def create_tensorboard_callback(dir_name, experiment_name):\n","    log_dir = dir_name + '/' + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n","    print(f\"Saving TensorBoard log files to: {log_dir}\")\n","    return tensorboard_callback\n"],"metadata":{"id":"bBz4j0hq-60h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Creating models using TensorFlowHub."],"metadata":{"id":"GjMay7qUAfGw"}},{"cell_type":"markdown","source":["we're going to use two models from TensorFlow Hub:\n","\n","* ResNetV2 - a state of the art computer vision model architecture from 2016.\n","* EfficientNet - a state of the art computer vision architecture from 2019."],"metadata":{"id":"-2_IPHAWAoPu"}},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras import layers"],"metadata":{"id":"-6zgI6Pj3qWc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Resnet 50 V2 feature vector\n","resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n","\n","# Original: EfficientNetB0 feature vector (version 1)\n","efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n","\n","# # New: EfficientNetB0 feature vector (version 2)\n","# efficientnet_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\""],"metadata":{"id":"Tqb0fqMn6dOs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's make a create_model () function to create a model from a URL\n","def create_model(model_url, num_classes=10):\n","  '''\n","  Creates a keras Sequential with the TensorFlow Hub Url\n","  \n","  Args:\n","   model_url (str) : A TensorFlow Hub feature extraction URL.\n","   num_classes (int): Number of output neurons in the ouput layer.\n","   \n","  Returns:\n","    An uncompiled Keras Sequential model with model_url as feature extactor layer and Dense output layer.\n","  '''\n","  # Download the pretrained model\n","  feature_extractor_layer = hub.KerasLayer(model_url,\n","                          trainable = False,\n","                          name= 'feature_extraction_layer',\n","                         input_shape = IMAGE_SHAPE+(3,))\n","  \n","  # Create or own model\n","  model = tf.keras.Sequential([\n","      feature_extractor_layer,\n","      layers.Dense(num_classes, activation= 'softmax', name= 'output_layer')\n","    ])\n","\n","  return model\n","\n","                    "],"metadata":{"id":"i81uXvA_7Qce"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Creating and testing  Resnet TensorFlow Hub Feature Extraction"],"metadata":{"id":"bVKPWcBX9gK8"}},{"cell_type":"code","source":["resnet_model = create_model(resnet_url,\n","                                            num_classes = train_data_10_percent.num_classes)"],"metadata":{"id":"yTuw1IPI-6M3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_10_percent.num_classes"],"metadata":{"id":"ynjiRlZN_F6r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resnet_model.summary()"],"metadata":{"id":"YmSs5i-oAP4w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile our resnet model\n","resnet_model.compile(loss='categorical_crossentropy',\n","                     optimizer= tf.keras.optimizers.Adam(),\n","                     metrics=[\"accuracy\"])"],"metadata":{"id":"tyAgfkRIAavM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's fit our Resnet model to the data (10 percent of 10 classes)\n","resnet_history = resnet_model.fit(train_data_10_percent,\n","                                  epochs=5,\n","                                  steps_per_epoch=len(train_data_10_percent),\n","                                  validation_data= test_data,\n","                                  validation_steps= len(test_data),\n","                                  callbacks=[create_tensorboard_callback(dir_name= 'tensorflow_hub',\n","                                                                         experiment_name=\"resnet50V2\"\n","                                                                         )])"],"metadata":{"id":"Wln8F0fZBGvu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's create a function to plot our loss curves.\n","import matplotlib.pyplot as plt\n","\n","# Plot the validation and training data separately\n","def plot_loss_curves(history):\n","  \"\"\"\n","  Returns separate loss curves for training and validation metrics.\n","  \"\"\" \n","  loss = history.history['loss']\n","  val_loss = history.history['val_loss']\n","\n","  accuracy = history.history['accuracy']\n","  val_accuracy = history.history['val_accuracy']\n","\n","  epochs = range(len(history.history['loss']))\n","\n","  # Plot loss\n","  plt.plot(epochs, loss, label='training_loss')\n","  plt.plot(epochs, val_loss, label='val_loss')\n","  plt.title('Loss')\n","  plt.xlabel('Epochs')\n","  plt.legend()\n","\n","  # Plot accuracy\n","  plt.figure()\n","  plt.plot(epochs, accuracy, label='training_accuracy')\n","  plt.plot(epochs, val_accuracy, label='val_accuracy')\n","  plt.title('Accuracy')\n","  plt.xlabel('Epochs')\n","  plt.legend();"],"metadata":{"id":"4k6CQlroCDQd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_loss_curves(resnet_history)"],"metadata":{"id":"tfTcXnimEMNc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Creating and testing EfficientNetB0 TensorFlow Hub Feature Extraction model."],"metadata":{"id":"tJ1Y4ySwERv6"}},{"cell_type":"code","source":["# Create EfficinetNetB0 feature extractor model\n","efficientnet_model = create_model(model_url= efficientnet_url,\n","                                  num_classes= train_data_10_percent.num_classes)\n","\n","# Compile EfficienteNet model\n","efficientnet_model.compile(loss= \"categorical_crossentropy\",\n","                           optimizer = tf.keras.optimizers.Adam(),\n","                           metrics= [\"accuracy\"]) \n","\n","# Fit EfficientNet model to 10% of training data\n","efficientnet_history = efficientnet_model.fit(train_data_10_percent,\n","                                              epochs=5,\n","                                              steps_per_epoch= len(train_data_10_percent),\n","                                              validation_data = test_data,\n","                                              validation_steps= len(test_data),\n","                                              callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n","                                                                                     experiment_name = \"efficientnetb0\")])\n","                                      "],"metadata":{"id":"mSsHaIRuFqu9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["efficientnet_model.summary()"],"metadata":{"id":"EMmSbPP8G7s0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Comparing the two models in tensorboard"],"metadata":{"id":"bdFrTnGsHjpt"}},{"cell_type":"code","source":["# Upload tensorBoard dev records.\n","!tensorboard dev upload --logdir ./tensorflow_hub/ \\\n","  --name \"EfficientNetB0 vs. ResNet50V2\" \\\n","  --description \"Comparing two different TF Hub feature extraction models architectures using 10% of training images\" \\\n","  --one_shot"],"metadata":{"id":"r8loWo3YtlkF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7HTevzg8uJAU"},"execution_count":null,"outputs":[]}]}